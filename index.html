<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Minigpt-4">
  <meta name="keywords" content="GPT-4, open-source, vision-language">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Minigpt-4</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
 <!--  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="icon" href="./static/images/icon.png">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  </head>

  <style>

    #main{
        position: relative;;
        width: 1200px;
    }

    .box{
        float: left;
        padding: 15px 0 0 15px;
        /*background-color: red;*/
    }

    .pic{
        padding: 10px;
        border: 1px solid #ccc;
        border-radius: 5px;
        background-color: #fff;
    }

    .pic img{
        width: 500px;
    }

  </style>



  <body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">MiniGPT-4:</h1>
          <h2 class="title is-2 publication-title">Enhancing the Vision-language Understanding with Advanced Large Language Models</h2>
          <div class="is-size-5">
            <span class="author-block">
                <a href="https://maureenzou.github.io/" style="color:#008AD7;font-weight:normal;">Deyao Zhu<sup>*</sup>
                </a>,                
            </span>
            <span class="author-block">
              <a href="https://zdou0830.github.io/" style="color:#008AD7;font-weight:normal;">Jun Chen<sup>*</sup></a>,</span>
            <span class="author-block">
              <a href="https://jwyang.github.io/" style="color:#008AD7;font-weight:normal;">Xiaoqian Shen</a>,
            </span>
            <span class="author-block">
              <a href="https://lx709.github.io/" style="color:#008AD7;font-weight:normal;">Xiang Li</a>,
            </span>
            <span class="author-block">
              <a href="https://zhegan27.github.io/" style="color:#008AD7;font-weight:normal;">Mohamed Elhoseiny</a>
            </span>
            <!-- <span class="author-block">
              <a href="https://www.microsoft.com/en-us/research/people/linjli/" style="color:#008AD7;font-weight:normal;">Linjie Li</a>,
            </span>
            <span class="author-block">
              <a href="https://chunyuan.li/" style="color:#00A4EF;font-weight:normal;">Chunyuan Li</a>,
            </span>  
            <span class="author-block">
              <a href="https://sites.google.com/site/xiyangdai/" style="color:#008AD7;font-weight:normal;">Xiyang Dai</a>,
            </span>   
            <span class="author-block">
              <a href="https://harkiratbehl.github.io/" style="color:#00A4EF;font-weight:normal;">Harkirat Behl</a>,
            </span>                                  
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=vJWEw_8AAAAJ&hl=en" style="color:#008AD7;font-weight:normal;">Jianfeng Wang</a>,
            </span>
            <span class="author-block">
              <a href="https://www.microsoft.com/en-us/research/people/luyuan/" style="color:#008AD7;font-weight:normal;">Lu Yuan</a>,
            </span>       
            <span class="author-block">
              <a href="https://vnpeng.net/" style="color:#F2A900;font-weight:normal;">Nanyun Peng</a>,
            </span>       
            <span class="author-block">
              <a href="https://www.microsoft.com/en-us/research/people/lijuanw/" style="color:#008AD7;font-weight:normal;">Lijuan Wang</a>,
            </span>    
            <span class="author-block">
              <a href="https://pages.cs.wisc.edu/~yongjaelee/" style="color:#f68946;font-weight:normal;">Yong Jae Lee<sup>&#x2628;</sup></a>,
            </span>                                                
            <span class="author-block">
              <a href="https://www.microsoft.com/en-us/research/people/jfgao/" style="color:#00A4EF;font-weight:normal;">Jianfeng Gao<sup>&#x2628;</sup></a>
            </span> -->
          </div>

          <br>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><b style="color:#008AD7; font-weight:normal">&#x25B6 </b> King Abdullah University of Science and Technology </span>
            <!-- <span class="author-block"><b style="color:#F2A900; font-weight:normal">&#x25B6 </b>UCLA; </span> -->
            <!-- <span class="author-block"><b style="color:#00A4EF; font-weight:normal">&#x25B6 </b>Microsoft Research, Redmond; </span> -->
            <!-- <span class="author-block"><b style="color:#008AD7; font-weight:normal">&#x25B6 </b>Microsoft Cloud & AI </span> -->
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup>Equal Contribution </span>
            <!-- <span class="author-block"><sup>&#x2628;</sup>Equal Advisory Contribution, </span> -->
            <!-- <span class="author-block"><sup>&#x2691;</sup>Project Lead </span> -->
          </div>

          <br>
         <!--  <div class="is-size-5 publication-authors">
            <span class="author-block"><b style="color:#e08ba0; font-weight:normal"> <b>In CVPR2023</b> </b></span>
          </div> -->


          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2212.11270.pdf" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/microsoft/X-Decoder/tree/main" target="_blank" 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

            <!--   <span class="link-block">
                <a href="https://github.com/microsoft/X-Decoder/tree/xgpt"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-hotjar"></i>
                  </span>
                  <span>MiniGPT-4</span>
                  </a>
              </span> -->

              <span class="link-block">
                <a href="https://huggingface.co/spaces/xdecoder/Demo"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-laugh-beam"></i>
                  </span>
                  <span>Huggingface Demo</span>
                  </a>
              </span>

             <!--  <span class="link-block">
                <a href="https://huggingface.co/spaces/xdecoder/Instruct-X-Decoder"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-laugh-beam"></i>
                  </span>
                  <span>Instruct Demo</span>
                  </a>
              </span>

              <span class="link-block">
                <a href="https://eval.ai/web/challenges/challenge-page/1931/overview"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-tree"></i>
                  </span>
                  <span>Challenge</span>
                  </a>
              </span> -->
              
              <span class="link-block">
                <a href="https://youtu.be/wYp6vmyolqE"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img id="teaser" width="120%" src="images_xdecoder/tittle_fig.gif">
      <h2 class="subtitle has-text-centered">
        <p style="font-family:Times New Roman"><b>Figure 1. X-Decoder is a single model trained to support a wide range of vision and vision-language tasks.</b></p>
      </h2>
    </div>
  </div>
</section>
 -->

<!-- <section class="hero teaser">
<div id="main">
  <div class="box"><div class="pic"><img src="demos/wop_2.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/cook_1.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/fix_1.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/rhyme_1.png" alt=""></div></div>
</div>
</section> -->


<link rel="stylesheet" href="js/index.css">

<section class="section">
  <div class="container is-max-desktop">

    <div class="container2">
      <div class="box_t">
        <img src="demos/wop_2.png">
        <!-- <span>CSS</span> -->
      </div>
      <div class="box_t">
        <img src="demos/cook_1.png">
        <!-- <span>Image</span> -->
      </div>
      <div class="box_t">
        <img src="demos/fix_1.png">
        <!-- <span>Hover</span> -->
      </div>
      <div class="box_t">
        <img src="demos/rhyme_1.png">
        <!-- <span>Effect</span> -->
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The recent GPT-4 has demonstrated extraordinary multi-modal abilities, such as directly generating websites from handwritten text and identifying humorous elements within images. These features are rarely observed in previous vision-language models. We believe the primary reason for GPT-4's advanced multi-modal generation capabilities lies in the utilization of a more advanced large language model (LLM). To examine this phenomenon, we present MiniGPT-4, which aligns a frozen visual encoder with a frozen LLM, Vicuna, using just one projection layer. Our findings reveal that MiniGPT-4 processes many capabilities similar to those exhibited by GPT-4 like detailed image description generation and website creation from hand-written drafts. Furthermore, we also observe other emerging capabilities in MiniGPT-4, including writing stories and poems inspired by given images, providing solutions to problems shown in images, teaching users how to cook based on food photos, etc. These advanced capabilities can be attributed to the use of a more advanced large language model. Furthermore, our method is computationally efficient, as we only train a projection layer using roughly 5 million aligned image-text pairs and an additional 3,500 carefully curated high-quality pairs. 
</b>
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <br>
    <br>
    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://user-images.githubusercontent.com/11957155/209045241-916ccf73-d29d-4637-8502-027d3420875c.mp4"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->

    <!--/ Demo. -->
    <!-- <br>
    <br>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Demo</h2>
      </div>
    </div>

    <div class="column is-full-width">
      <div class="columns is-centered">
        <img id="teaser" width="90%" src="images/demo6_AdobeExpress.gif">
      </div>
      <div class="columns is-centered">
      <h1>
        <p style="font-family:Times New Roman"><b>X-GPT: Connecting generalist X-Decoder with GPT-3</b>
      </h1>                 
      </div>
    </div>

    <br>

    <div class="column is-full-width">
      <div class="columns is-centered">
        <img id="teaser" width="90%" src="images/inpaint.gif">
      </div>
      <div class="columns is-centered">
      <h1>
        <p style="font-family:Times New Roman"><b>Instruct-X-Decoder: Object-centric instructional image editing</b>
      </h1>                 
      </div>
    </div> -->

    <!--/ Paper video. -->
    <br>
    <br>
    <!-- Paper Model. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3">Model</h2>
        <div class="content has-text-justified">
          <p>
            <b>MiniGPT-4 consists of a vision encoder with a pretrained ViT and Q-Former, a single linear projection layer, and an advanced Vicuna large language model. MiniGPT-4 only requires training the linear layer to align the visual features with the Vicuna.</b>:
          </p>
          <ul>
            <!-- <li>It has two types of queries (latent queries and text queries) and outputs (semantic outputs and pixel-level outputs).</li>
            <li>It uses a single text encoder for all text corpus, ranging from class concepts, referring phrases to image captions.</li>
            <li>It decouples image and text encoder to accomadate cross-image tasks (e.g., image-text retrieval) and within-image tasks (e.g., segmentation and captioning).</li> -->

          </ul>
        </div>  
        <img id="model" width="80%" src="images/overview.png">
        <h3 class="subtitle has-text-centered">
          <p style="font-family:Times New Roman"><b>The architecture of MiniGPT-4.</b></p>
        </h3>   
        <br>
        <br>

      </div>
    </div>
    <br>
    <br>    
    <!--/ Paper video. -->
  </div>
</section>

<!-- 
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>

@article{zou2022xdecoder,
  author      = {Zou*, Xueyan and Dou*, Zi-Yi and Yang*, Jianwei and Gan, Zhe and Li, Linjie and Li, Chunyuan and Dai, Xiyang and Wang, Jianfeng and Yuan, Lu and Peng, Nanyun and Wang, Lijuan and Lee^, Yong Jae and Gao^, Jianfeng},
  title       = {Generalized Decoding for Pixel, Image and Language},
  publisher   = {arXiv:2212.11270v1},
  year        = {2022},
}
</code></pre>
  </div>
</section> -->

<section class="section" id="Acknowledgement">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgement</h2>
    <p>
      This website is adapted from <a
      href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, licensed under a <a rel="license"
                                          href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
      Commons Attribution-ShareAlike 4.0 International License</a>.
    </p>
  </div>
</section>

<!-- 
<div class="main">
  <img src="demos/ad_1.png">
  <img src="demos/ad_2.png">
  <img src="demos/cook_1.png">
  <img src="demos/cook_2.png">
  <img src="demos/fact_1.png">
  <img src="demos/fact_2.png">
  <img src="demos/fix_1.png">
  <img src="demos/fix_2.png">
  <img src="demos/fun_1.png">
  <img src="demos/fun_2.png">
  <img src="demos/people_1.png">
  <img src="demos/people_2.png">
  <img src="demos/rhyme_1.png">
  <img src="demos/rhyme_2.png">
  <img src="demos/story_1.png">
  <img src="demos/story_2.png">
  <img src="demos/wop_1.png">
  <img src="demos/wop_2.png">
</div> -->

<section class="section">
  <!-- Results. -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-six-fifths">
      <h2 class="title is-3">Results</h2>
      </div>
    </div>
  </div>
  <!--/ Results. -->    
<div class="container is-max-desktop">
</section>

<script src="js/Underscore-min.js"></script>
<!-- <script src="js/myFunc.js"></script> -->
<script src="js/index.js"></script>

<section class="section">


<div id="main">
  <div class="box"><div class="pic"><img src="demos/ad_1.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/ad_2.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/cook_2.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/web_1.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/describe_2.png" alt=""></div></div>


  <div class="box"><div class="pic"><img src="demos/fact_1.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/fact_2.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/fix_2.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/fun_1.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/fun_2.png" alt=""></div></div>

  <div class="box"><div class="pic"><img src="demos/logo_1.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/logo_2.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/op_1.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/op_2.png" alt=""></div></div>

  <div class="box"><div class="pic"><img src="demos/wop_1.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/people_2.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/rhyme_2.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/story_1.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/story_2.png" alt=""></div></div>
  
  <div class="box"><div class="pic"><img src="demos/describe_1.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/web_2.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/people_1.png" alt=""></div></div>


</div>

</section>




</body>

</html>
