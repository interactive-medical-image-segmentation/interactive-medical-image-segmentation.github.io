<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Interactive Medical Image Segmentation">
  <meta name="keywords" content="GPT-4, open-source, vision-language">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Interactive Medical Image Segmentation</title>

  <!-- Global site tag (gtag.js) - Google Analytics
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <meta name="google-site-verification" content="6lbYN1vX7A4sD8SrVniq84UEKyEUSBgxeP7d3FjuuK0" />

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <!-- <link rel="icon" href="./static/images/icon.png"> -->
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/nav.css">
  <link rel="shortcut icon" href="path/to/favicon.ico" type="image/x-icon">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<style>
  #main {
    position: relative;
    ;
    width: 1200px;
  }

  .box {
    float: left;
    padding: 15px 0 0 15px;
    /*        background-color: red;*/
  }

  .pic {
    width: 500px;
    padding: 10px;
    border: 1px solid #ccc;
    border-radius: 5px;
    background-color: #fff;
  }

  .pic img {
    width: 500px;
  }
</style>



<body>
  <section class="hero">
    <div class="hero-body">
      <div class="wrapper container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Interactive Medical Image Segmentation</h1>

            <div class="content has-text-justified">
              <p>
                <!-- blue font -->
                <!-- <span style="color:#008AD7;font-weight:bold">GPT-4 says: </span> -->
                Interactive Medical Image Segmentation is a key aspect of modern healthcare, significantly enhancing
                diagnostic accuracy and patient care. By providing precise images of anatomical structures and
                pathological regions, it enables clinicians to make informed decisions about treatment plans. This field
                also promotes time and cost efficiency through the use of automated tools, facilitating personalized
                medicine and interdisciplinary collaboration. Ultimately, Interactive Medical Image Segmentation
                contributes to improved patient outcomes, healthcare quality, and medical research advancements.
              </p>
              <img src="images/fig-revised_interaction.png">
              <h3 class="subtitle has-text-centered">
                <div align="center">
                  <p style="font-family:Times New Roman"><b>The architecture of Interactive Medical Image
                      Segmentation</b></p>
                </div>
              </h3>
            </div>
            <!-- tab -->
            <ul class="nav nav-tabs" id="myTab" role="tablist">
              <li class="nav-item" style="margin-left: 2px;">
                <a class="nav-link active" data-toggle="tab" href="#tab1" role="tab" aria-controls="human"
                  style="background-color:azure;">With Multi-Agent Reinforcement Learning</a>
              </li>
              <li class="nav-item" style="margin-left: 10px;">
                <a class="nav-link" data-toggle="tab" href="#tab2" role="tab" aria-controls="gpt4"
                  style="background-color:azure;">With Self-adaptive Confidence Calibration</a>
              </li>
              <li class="nav-item" style="margin-left: 10px;">
                <a class="nav-link" data-toggle="tab" href="#tab3" role="tab" aria-controls="unnatural"
                  style="background-color:azure;">Temporally-Extended Prompts Optimization</a>
              </li>
            </ul>
            <!-- tab contents -->
            <div class="tab-content">
              <div id="tab1" class="tab-pane active" role="tabpanel">
                <section class="before">
                  <div class="before-body">
                    <div class="container is-max-desktop">
                      <div class="columns is-centered">
                        <div class="column has-text-centered">
                          <h3 class="title is-2 publication-title">Iteratively-Refined Interactive 3d Medical Image
                            Segmentation with Multi-Agent Reinforcement Learning</h3>
                          <div class="is-size-5">
                            <div class="authors">
                              <span class="author-block">
                                <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liao,+X"
                                  style="color:#008AD7;font-weight:normal;">Xuan Liao</a>,
                              </span>
                              <span class="author-block">
                                <a href="https://scholar.google.com.hk/citations?user=HAtzuaYAAAAJ"
                                  style="color:#F2A900;font-weight:normal;">Wenhao Li*</a>,
                              </span>
                              <span class="author-block">
                                <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+Q"
                                  style="color:#F2A900;font-weight:normal;">Qisen Xu*</a>,
                              </span>
                              <span class="author-block">
                                <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+X"
                                  style="color:#F2A900;font-weight:normal;">Xiangfeng Wang</a>,
                              </span>
                              <span class="author-block">
                                <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin,+B"
                                  style="color:#F2A900;font-weight:normal;">Bo Jin</a>,
                              </span>
                              <span class="author-block">
                                <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+X"
                                  style="color:#008AD7;font-weight:normal;">Xiaoyun Zhang</a>,
                              </span>
                              <span class="author-block">
                                <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+Y"
                                  style="color:#008AD7;font-weight:normal;">Ya Zhang</a>,
                              </span>
                              <span class="author-block">
                                <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+Y"
                                  style="color:#008AD7;font-weight:normal;">Yanfeng Wang</a>
                              </span>
                            </div>


                          </div>


                          <div class="is-size-5 publication-authors">
                            <span class="author-block"><b style="color:#008AD7; font-weight:normal">&#x25B6 </b>
                              Shanghai Jiao Tong University </span>
                            <span class="author-block"><b style="color:#F2A900; font-weight:normal">&#x25B6 </b> East
                              China Normal
                              University </span>
                          </div>

                          <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>*</sup>Equal Contribution </span>
                            <!-- <span class="author-block"><sup>&#x2628;</sup>Equal Advisory Contribution, </span> -->
                            <!-- <span class="author-block"><sup>&#x2691;</sup>Project Lead </span> -->
                          </div>


                          <!--  <div class="is-size-5 publication-authors">
                          <span class="author-block"><b style="color:#e08ba0; font-weight:normal"> <b>In CVPR2023</b> </b></span>
                        </div> -->


                          <div class="column has-text-centered">
                            <div class="publication-links">
                              <span class="link-block">
                                <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Liao_Iteratively-Refined_Interactive_3D_Medical_Image_Segmentation_With_Multi-Agent_Reinforcement_Learning_CVPR_2020_paper.pdf"
                                  target="_blank" class="external-link button is-normal is-rounded is-dark">
                                  <span class="icon">
                                    <i class="ai ai-arxiv"></i>
                                  </span>
                                  <span>Paper</span>
                                </a>
                              </span>

                              <span class="link-block">
                                <a href="https://github.com/Chuyun-Shen/Interactive-Medical-Image-Segmentation-with-MARL/" target="_blank"
                                  class="external-link button is-normal is-rounded is-dark">
                                  <span class="icon">
                                    <i class="fab fa-github"></i>
                                  </span>
                                  <span>Code</span>
                                </a>
                              </span>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                </section>


                <link rel="stylesheet" type="text/css" href="js/simple_style.css" />


                <section class="section">
                  <div class="wrapper is-max-desktop">
                    <!-- Abstract. -->
                    <div class="columns is-centered has-text-centered">
                      <div class="column is-four-fifths">
                        <h2 class="title is-3">Abstract</h2>
                        <div class="content has-text-justified">
                          <p>Existing automatic 3D image segmentation methods usually fail to meet the clinic use. Many
                            studies have explored an interactive strategy to improve the image segmentation performance
                            by iteratively incorporating user hints. However, the dynamic process for successive
                            interactions is largely ignored. We here propose to model the dynamic process of iterative
                            interactive image segmentation as a Markov decision process (MDP) and solve it with
                            reinforcement learning (RL). Unfortunately, it is intractable to use single-agent RL for
                            voxel-wise prediction due to the large exploration space. To reduce the exploration space to
                            a tractable size, we treat each voxel as an agent with a shared voxel-level behavior
                            strategy so that it can be solved with multi-agent reinforcement learning. An additional
                            advantage of this multi-agent model is to capture the dependency among voxels for
                            segmentation task. Meanwhile, to enrich the information of previous segmentations, we
                            reserve the prediction uncertainty in the state space of MDP and derive an adjustment action
                            space leading to a more precise and finer segmentation. In addition, to improve the
                            efficiency of exploration, we design a relative cross-entropy gain-based reward to update
                            the policy in a constrained direction. Experimental results on various medical datasets have
                            shown that our method significantly outperforms existing state-of-the-art methods, with the
                            advantage of fewer interactions and a faster convergence.
                          </p>
                        </div>
                      </div>
                    </div>



                    <!-- Paper Model. -->

                    <div class="columns is-centered has-text-centered">
                      <div class="column is-six-fifths">
                        <h2 class="title is-3">Model</h2>
                        <div class="content has-text-justified">
                          <p>This paper proposes
                            a novel interactive medical image segmentation update
                            method called <em>Iteratively-Refined interactive 3D medical
                              image segmentation via Multi-agent Reinforcement Learning (IteR-MRL)</em>. We formulate
                            the dynamic process of iterative interactive image segmentation as an MDP. Specifically, at
                            each refinement step, the model needs to decide
                            the labels of all voxels, according to the previous segmentations and supervision
                            information from the interaction. After that, the model will get the feedback according to
                            predefined measurement of segmentation, and the above process will be repeated until the
                            maximum number of interactions is reached. We then adopt the RL methods to solve
                            the MDP above, that is, to find the segmentation strategy
                            to maximize the accumulated rewards received at each refinement step. However, it will be
                            intractable to use singleagent RL for voxel-wise prediction due to the large exploration
                            space. In addition, considering that the voxels in the
                            segmentation task are interdependent, they can achieve better segmentation by a more
                            comprehensive grasp of the surrounding information. To reduce the exploration space to
                            a tractable size and explicitly model the dependencies between voxels, we introduce the
                            multi-agent reinforcement
                            learning (MARL) method.
                          </p>
                          <img src="images/Iter_frame.png">
                          <h3 class="subtitle has-text-centered">
                            <div align="center">
                              <p style="font-family:Times New Roman"><b>Overview of Iteratively-Refined interactive 3D
                                  medical image segmentation algorithm based on MARL </b></p>
                            </div>
                          </h3>
                        </div>
                      </div>
                    </div>


                    <!--/ Paper video. -->
                  </div>
                </section>

                <section class="section">
                  <!-- Results. -->
                  <div class="columns is-centered has-text-centered">
                    <div class="column is-six-fifths">
                      <h2 class="title is-3">Results</h2>
                    </div>
                  </div>
                  <div class="container is-max-desktop">
                </section>

                <!-- Paper Model. -->

                <div class="columns is-centered has-text-centered">
                  <div class="column is-six-fifths">
                    <div class="content has-text-justified">
                      <img src="images/inter_tab1.png">
                      <h3 class="subtitle has-text-centered">
                        <div align="center">
                          <p style="font-family:Times New Roman"><b>Table 1: Combination with different initial methods
                              methods</b></p>
                        </div>
                      </h3>
                    </div>

                    <br>


                    <div class="content has-text-justified">
                      <img src="images/inter_tab2.png" class="resized-image">
                      <h3 class="subtitle has-text-centered">
                        <div align="center">
                          <p style="font-family:Times New Roman"><b>Table 2: Performance improvement in one interactive
                              sequence</b></p>
                        </div>
                      </h3>
                    </div>

                    <br>

                    <div class="content has-text-justified">
                      <img src="images/inter_res1.png">
                      <h3 class="subtitle has-text-centered">
                        <div align="center">
                          <p style="font-family:Times New Roman"><b> The visualization for the relation between
                              predictions and hints.
                              (a) The visualization of one click and its influence on prediction and hint maps.
                              (b) The visualization of prediction and hint map for each step.</b></p>
                        </div>
                      </h3>
                    </div>

                  </div>
                </div>

                <section class="section" id="BibTeX">
                  <div class="container is-max-desktop content">
                    <h2 class="title">BibTeX</h2>
                    <pre><code>@inproceedings{liao2020iteratively,
  title={Iteratively-refined interactive 3D medical image segmentation with multi-agent reinforcement learning},
  author={Liao, Xuan and Li, Wenhao and Xu, Qisen and Wang, Xiangfeng and Jin, Bo and Zhang, Xiaoyun and Wang, Yanfeng and Zhang, Ya},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={9394--9402},
  year={2020}
}</code></pre>
                  </div>
                </section>

                <!-- <section class="section">
                  <div id="main">
                    <div class="box">
                      <div class="pic"><img src="demos/fact_1.png" alt=""></div>
                    </div>
                    <div class="box">
                      <div class="pic"><img src="demos/fact_2.png" alt=""></div>
                    </div>
                    <div class="box">
                      <div class="pic"><img src="demos/fix_2.png" alt=""></div>
                    </div>
                    <div class="box">
                      <div class="pic"><img src="demos/fun_1.png" alt=""></div>
                    </div>
                    <div class="box">
                      <div class="pic"><img src="demos/fun_2.png" alt=""></div>
                    </div>
                  </div>

                </section> -->
              </div>
              <div id="tab2" class="tab-pane" role="tabpanel">
                <section class="before">
                  <div class="before-body">
                    <div class="container is-max-desktop">
                      <div class="columns is-centered">
                        <div class="column has-text-centered">
                          <h3 class="title is-2 publication-title">Interactive medical image segmentation with
                            self-adaptive
                            confidence calibration</h3>
                          <div class="is-size-5">
                            <span class="author-block">
                              <a href="https://scholar.google.com.hk/citations?user=sB4jZ54AAAAJ"
                                style="color:#008AD7;font-weight:normal;">Chuyun
                                Shen</a>,
                            </span>
                            <span class="author-block">
                              <a href="https://scholar.google.com.hk/citations?user=HAtzuaYAAAAJ"
                                style="color:#F2A900;font-weight:normal;">Wenhao
                                Li</a>,
                            </span>
                            <span class="author-block">
                              <a href="#" style="color:#008AD7;font-weight:normal;">Qisen Xu</a>,
                            </span>
                            <span class="author-block">
                              <a href="#" style="color:#3e8a2ce3;font-weight:normal;">Bin Hu</a>,
                            </span>
                            <span class="author-block">
                              <a href="#" style="color:#b52390;font-weight:normal;">Bo Jin</a>,
                            </span>
                            <span class="author-block">
                              <a href="#" style="color:#008AD7;font-weight:normal;">Haibin Cai</a>,
                            </span>
                            <span class="author-block">
                              <a href="#" style="color:#3e8a2ce3;font-weight:normal;">Fengping Zhu</a>,
                            </span>
                            <span class="author-block">
                              <a href="#" style="color:#3e8a2ce3;font-weight:normal;">Yuxin Li</a>,
                            </span>
                            <span class="author-block">
                              <a href="#" style="color:#008AD7;font-weight:normal;">Xiangfeng Wang</a>
                            </span>

                          </div>


                          <div class="is-size-5 publication-authors">
                            <span class="author-block"><b style="color:#008AD7; font-weight:normal">&#x25B6 </b> East
                              China Normal
                              University </span>
                            <span class="author-block"><b style="color:#F2A900; font-weight:normal">&#x25B6 </b> The
                              Chinese
                              University of Hong Kong, Shenzhen </span>
                            <span class="author-block"><b style="color:#3e8a2ce3; font-weight:normal">&#x25B6
                              </b>Huashan Hospital
                            </span>
                            <span class="author-block"><b style="color:#b52390; font-weight:normal">&#x25B6 </b>Tongji
                              University
                            </span>
                          </div>

                          <div class="is-size-5 publication-authors">
                            <!-- <span class="author-block"><sup>*</sup>Equal Contribution </span> -->
                            <!-- <span class="author-block"><sup>&#x2628;</sup>Equal Advisory Contribution, </span> -->
                            <!-- <span class="author-block"><sup>&#x2691;</sup>Project Lead </span> -->
                          </div>


                          <!--  <div class="is-size-5 publication-authors">
                          <span class="author-block"><b style="color:#e08ba0; font-weight:normal"> <b>In CVPR2023</b> </b></span>
                        </div> -->


                          <div class="column has-text-centered">
                            <div class="publication-links">
                              <span class="link-block">
                                <a href="https://link.springer.com/article/10.1631/FITEE.2200299" target="_blank"
                                  class="external-link button is-normal is-rounded is-dark">
                                  <span class="icon">
                                    <i class="ai ai-arxiv"></i>
                                  </span>
                                  <span>Paper</span>
                                </a>
                              </span>

                              <span class="link-block">
                                <a href="https://github.com/Chuyun-Shen/Interactive-Medical-Image-Segmentation-with-MARL/" target="_blank"
                                  class="external-link button is-normal is-rounded is-dark">
                                  <span class="icon">
                                    <i class="fab fa-github"></i>
                                  </span>
                                  <span>Code</span>
                                </a>
                              </span>

                              <span class="link-block">
                                <a href="https://bit.ly/mecca-demo-video" target="_blank"
                                  class="external-link button is-normal is-rounded is-dark">
                                  <span class="icon">
                                    <i class="fab fa-youtube"></i>
                                  </span>
                                  <span>Video</span>
                                </a>
                              </span>

                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                </section>


                <link rel="stylesheet" type="text/css" href="js/simple_style.css" />


                <section class="section">
                  <div class="wrapper is-max-desktop">
                    <!-- Abstract. -->
                    <div class="columns is-centered has-text-centered">
                      <div class="column is-four-fifths">
                        <h2 class="title is-3">Abstract</h2>
                        <div class="content has-text-justified">
                          <p>Interactive medical segmentation based on human-in-the-loop machine learning is a novel
                            paradigm that
                            draws on human expert knowledge to assist medical image segmentation. However, existing
                            methods often
                            fall into what we call <em>interactive misunderstanding</em>, the essence of which is the
                            dilemma in
                            trading off <em>short-</em> and <em>long-term</em> interaction information. To better
                            utilize the
                            interactive information at various timescales, we propose an interactive segmentation
                            framework, called
                            interactive <strong>ME</strong>dical segmentation with self-adaptive
                            <strong>C</strong>onfidence
                            <strong>CA</strong>libration (<strong>MECCA</strong>), which combines action-based
                            confidence learning
                            and multi-agent reinforcement learning. A novel confidence network is learned by predicting
                            the
                            alignment level of the action with the short-term interactive information. A
                            confidence-based
                            reward-shaping mechanism is then proposed to explicitly incorporate confidence in the policy
                            gradient
                            calculation, thus directly correcting the model's interactive misunderstanding. MECCA also
                            enables
                            user-friendly interactions by reducing the interaction intensity and difficulty via label
                            generation and
                            interaction guidance, respectively. Numerical experiments on different segmentation tasks
                            show that
                            MECCA can significantly improve short- and long-term interactive information utilization
                            efficiency with
                            remarkably fewer labeled samples.
                          </p>
                        </div>
                      </div>
                    </div>



                    <!-- Paper Model. -->

                    <div class="columns is-centered has-text-centered">
                      <div class="column is-six-fifths">
                        <h2 class="title is-3">Model</h2>
                        <div class="content has-text-justified">
                          <p>
                            The segmentation module outputs actions to change the segmentation probability of each
                            voxel (agent) at each interaction step. Meanwhile, the confidence network estimating the
                            confidence of the actions will generate the self-adaptive reward and simulated label. The
                            confidence map can provide the advice regions of the next interaction step to experts. 
                          </p>
                          <img src="images/fig-revised_framework.png">
                          <h3 class="subtitle has-text-centered">
                            <div align="center">
                              <p style="font-family:Times New Roman"><b>Interactive medical image segmentation with
                                  self-adaptive confidence calibration</b></p>
                            </div>
                          </h3>
                        </div>
                      </div>
                    </div>


                    <!--/ Paper video. -->
                  </div>
                </section>

                <section class="section">
                  <!-- Results. -->
                  <div class="columns is-centered has-text-centered">
                    <div class="column is-six-fifths">
                      <h2 class="title is-3">Results</h2>
                    </div>
                  </div>
                  <div class="container is-max-desktop">
                </section>

                <!-- Paper Model. -->

                <div class="columns is-centered has-text-centered">
                  <div class="column is-six-fifths">
                    <div class="content has-text-justified">
                      <img src="images/mecca_tab1.png">
                      <h3 class="subtitle has-text-centered">
                        <div align="center">
                          <p style="font-family:Times New Roman"><b>Quantitative comparison of different
                              methods</b></p>
                        </div>
                      </h3>
                    </div>

                    <br>

                    <div class="content has-text-justified">
                      <img src="images/mecca_dice.png">
                      <h3 class="subtitle has-text-centered">
                        <div align="center">
                          <p style="font-family:Times New Roman"><b>The performance of different interactive medical
                              segmentation methods and methods with different weighting rewards.
                            </b></p>
                        </div>
                      </h3>
                    </div>

                  </div>
                </div>

                <section class="section" id="BibTeX">
                  <div class="container is-max-desktop content">
                    <h2 class="title">BibTeX</h2>
                    <pre><code>@article{shen2023interactive,
  title={Interactive medical image segmentation with self-adaptive confidence calibration},
  author={Shen, Chuyun and Li, Wenhao and Xu, Qisen and Hu, Bin and Jin, Bo and Cai, Haibin and Zhu, Fengping and Li, Yuxin and Wang, Xiangfeng},
  journal={Frontiers of Information Technology \& Electronic Engineering},
  volume={24},
  number={9},
  pages={1332--1348},
  year={2023},
  publisher={Springer}
}</code></pre>
                  </div>
                </section>

                <!-- <section class="section">
                  <div id="main">
                    <div class="box">
                      <div class="pic"><img src="demos/fact_1.png" alt=""></div>
                    </div>
                    <div class="box">
                      <div class="pic"><img src="demos/fact_2.png" alt=""></div>
                    </div>
                    <div class="box">
                      <div class="pic"><img src="demos/fix_2.png" alt=""></div>
                    </div>
                    <div class="box">
                      <div class="pic"><img src="demos/fun_1.png" alt=""></div>
                    </div>
                    <div class="box">
                      <div class="pic"><img src="demos/fun_2.png" alt=""></div>
                    </div>
                  </div>

                </section> -->
              </div>
              <div id="tab3" class="tab-pane" role="tabpanel">
                <div id="tab3" class="tab-pane active" role="tabpanel">
                  <section class="before">
                    <div class="before-body">
                      <div class="container is-max-desktop">
                        <div class="columns is-centered">
                          <div class="column has-text-centered">
                            <h3 class="title is-2 publication-title">Temporally-Extended Prompts Optimization for SAM in Interactive Medical Image Segmentation</h3>
                            <div class="is-size-5">
                              <div class="authors">
                                <span class="author-block">
                                  <a href="https://scholar.google.com.hk/citations?user=sB4jZ54AAAAJ"
                                    style="color:#008AD7;font-weight:normal;">Chuyun
                                    Shen</a>,
                                </span>
                                <span class="author-block">
                                  <a href="https://scholar.google.com.hk/citations?user=HAtzuaYAAAAJ"
                                    style="color:#149926;font-weight:normal;">Wenhao Li</a>,
                                </span>
                                <span class="author-block">
                                  <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+Y"
                                    style="color:#F2A900;font-weight:normal;">Ya Zhang</a>,
                                </span>
                                <span class="author-block">
                                  <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+Y"
                                    style="color:#F2A900;font-weight:normal;">Yanfeng Wang</a>,
                                </span>
                                <span class="author-block">
                                  <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+X"
                                    style="color:#008AD7;font-weight:normal;">Xiangfeng Wang</a>
                                </span>
                              </div>


                            </div>


                            <div class="is-size-5 publication-authors">
                              <span class="author-block"><b style="color:#008AD7; font-weight:normal">&#x25B6 </b> East
                                China Normal University
                              </span>
                              <span class="author-block"><b style="color:#149926; font-weight:normal">&#x25B6 </b> The
                                Chinese University of Hong Kong, Shenzhen </span>
                              <span class="author-block"><b style="color:#F2A900; font-weight:normal">&#x25B6 </b>
                                Shanghai Jiao Tong University </span>
                            </div>

                            <!-- <div class="is-size-5 publication-authors"> -->
                            <!-- <span class="author-block"><sup>*</sup>Equal Contribution </span> -->
                            <!-- <span class="author-block"><sup>&#x2628;</sup>Equal Advisory Contribution, </span> -->
                            <!-- <span class="author-block"><sup>&#x2691;</sup>Project Lead </span> -->
                            <!-- </div> -->


                            <!--  <div class="is-size-5 publication-authors">
                              <span class="author-block"><b style="color:#e08ba0; font-weight:normal"> <b>In CVPR2023</b> </b></span>
                            </div> -->


                            <div class="column has-text-centered">
                              <div class="publication-links">
                                <span class="link-block">
                                  <a href="https://arxiv.org/abs/2306.08958" target="_blank"
                                    class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                      <i class="ai ai-arxiv"></i>
                                    </span>
                                    <span>Paper</span>
                                  </a>
                                </span>

                                <span class="link-block">
                                  <a href="https://github.com/Chuyun-Shen/TEPO" target="_blank"
                                    class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                      <i class="fab fa-github"></i>
                                    </span>
                                    <span>Code</span>
                                  </a>
                                </span>
                              </div>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                  </section>


                  <link rel="stylesheet" type="text/css" href="js/simple_style.css" />


                  <section class="section">
                    <div class="wrapper is-max-desktop">
                      <!-- Abstract. -->
                      <div class="columns is-centered has-text-centered">
                        <div class="column is-four-fifths">
                          <h2 class="title is-3">Abstract</h2>
                          <div class="content has-text-justified">
                            <p>The <i>Segmentation Anything Model</i> (SAM) has recently emerged as a foundation model
                              for addressing image segmentation. Owing to the intrinsic complexity of medical images and
                              the high annotation cost, the medical image segmentation (MIS) community has been
                              encouraged to investigate SAM's zero-shot capabilities to facilitate automatic annotation.
                              Inspired by the extraordinary accomplishments of the <i>interactive</i> medical image
                              segmentation (IMIS) paradigm, this paper focuses on assessing the potential of SAM's
                              zero-shot capabilities within the IMIS paradigm to amplify its benefits in the MIS domain.
                              Regrettably, we observe that SAM's vulnerability to prompt forms (e.g., points, bounding
                              boxes) becomes notably pronounced in IMIS. This leads us to develop a mechanism that
                              adaptively offers suitable prompt forms for human experts. We refer to the mechanism above
                              as <i>temporally-extended prompts optimization</i> (TEPO) and model it as a Markov
                              decision process, solvable through reinforcement learning. Numerical experiments on the
                              standardized benchmark Brats2020 demonstrate that the learned TEPO agent can
                              further enhance SAM's zero-shot capability in the MIS context.
                            </p>
                          </div>
                        </div>
                      </div>



                      <!-- Paper Model. -->

                      <div class="columns is-centered has-text-centered">
                        <div class="column is-six-fifths">
                          <h2 class="title is-3">Model</h2>
                          <div class="content has-text-justified">
                            <p> In an unprecedented discovery, we ascertain that sequential prompt forms constitute the
                              crucial elements influencing the zero-shot performance of SAM in IMIS, subsequently
                              proposing a pertinent temporally-extended prompts optimization problem;
                              By conceptualizing the temporally-extended prompts optimization as an MDP, we employ RL to
                              optimize the sequential selection of prompt forms, thereby enhancing the zero-shot
                              performance of SAM in IMIS；
                              The performance juxtaposition and ablation studies conducted on the standardized benchmark
                              Brats2020 substantiate the efficacy of the TEPO agent in ameliorating SAM's
                              zero-shot capability.

                            </p>
                            <img src="images/TEPO.png">
                            <h3 class="subtitle has-text-centered">
                              <div align="center">
                                <p style="font-family:Times New Roman"><b>The architecture of our proposed TEPO </b></p>
                              </div>
                            </h3>
                            <img src="images/alg.png">
                          </div>
                        </div>
                      </div>


                      <!--/ Paper video. -->
                    </div>
                  </section>

                  <section class="section">
                    <!-- Results. -->
                    <div class="columns is-centered has-text-centered">
                      <div class="column is-six-fifths">
                        <h2 class="title is-3">Results</h2>
                      </div>
                    </div>
                    <div class="container is-max-desktop">
                  </section>

                  <!-- Paper Model. -->

                  <div class="columns is-centered has-text-centered">
                    <div class="column is-six-fifths">
                      <div class="content has-text-justified">
                        <img src="images/TEPO_tab1.png", style="width: 95%;">
                        <h3 class="subtitle has-text-centered">
                          <div align="center">
                            <p style="font-family:Times New Roman"><b>Table 1: Action Selection Preferences and
                                Quantitative Segmentation Performance for TEPO Policies and rule-based methods, using
                                consistent labels: "Fore" (forehead point form), "Back" (background point form),
                                "Center" (center point form), and "Bbox" (bounding box form). This table presents a
                                comparative analysis of TEPO-based methods. The highest Dice score for each step is
                                highlighted in <strong>bold</strong> (Throughout all methods). Results for rule-based
                                methods comparisons are provided in the subsequent table.
                              </b></p>
                          </div>
                        </h3>
                      </div>

                      <br>

                      <div class="content has-text-justified">
                        <img src="images/TEPO_dice.png" class="resized-image2">
                        <h3 class="subtitle has-text-centered">
                          <div align="center">
                            <p style="font-family:Times New Roman"><b> The performance improvement of different
                                interactive medical
                                segmentation methods at different interaction steps. All these test results
                                are performed on the Brats2020 dataset.</b></p>
                          </div>
                        </h3>
                      </div>

                      <br>

                      <div class="content has-text-justified">
                        <img src="images/TEPO_vis.png">
                        <h3 class="subtitle has-text-centered">
                          <div align="center">
                            <p style="font-family:Times New Roman"><b> Visualization of strategies and results of different
                                strategies on the same medical image. The green pentagram indicates the foreground, the red
                                pentagram indicates the background, and the green box indicates the bounding box.</b></p>
                          </div>
                        </h3>
                      </div>

                    </div>
                  </div>

                  <section class="section" id="BibTeX">
                    <div class="container is-max-desktop content">
                      <h2 class="title">BibTeX</h2>
                      <pre><code>@inproceedings{shen2023temporally,
  title={Temporally-Extended Prompts Optimization for SAM in Interactive Medical Image Segmentation},
  author={Shen, Chuyun and Li, Wenhao and Zhang, Ya and Wang, Yanfeng and Wang, Xiangfeng},
  booktitle={Machine Learning for Biological and Medical Image Big Data Workshop of 2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
  year={2023}
}</code></pre>
                    </div>
                  </section>
                  
                </div>
              </div>



              <!-- <section class="section">
                      <div id="main">
                        <div class="box">
                          <div class="pic"><img src="demos/fact_1.png" alt=""></div>
                        </div>
                        <div class="box">
                          <div class="pic"><img src="demos/fact_2.png" alt=""></div>
                        </div>
                        <div class="box">
                          <div class="pic"><img src="demos/fix_2.png" alt=""></div>
                        </div>
                        <div class="box">
                          <div class="pic"><img src="demos/fun_1.png" alt=""></div>
                        </div>
                        <div class="box">
                          <div class="pic"><img src="demos/fun_2.png" alt=""></div>
                        </div>
                      </div>
                  
                    </section> -->
            </div>
          </div>
        </div>
      </div>
    </div>
    </div>
  </section>

  <script> let currTab = 1; document.addEventListener('click', e => { if (e.target.getAttribute('data-toggle') === "tab") { e.preventDefault(); let preLink = document.querySelector(`a[href='#tab${currTab}']`); if (preLink == e.target) { return; } let preActive = document.getElementById(`tab${currTab}`); let id = e.target.getAttribute('href').slice(1); let nextActive = document.getElementById(id); preActive.classList.remove("active"); preLink.classList.remove("active"); nextActive.classList.add("active"); e.target.classList.add("active"); currTab = Number(id[3]); } }) </script>


</body>

</html>